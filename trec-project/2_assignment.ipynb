{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc2c729",
   "metadata": {},
   "source": [
    "## 1. Setup: Connecting to Elasticsearch and preparing trec_eval\n",
    "In this step, we make sure our environment is ready. \n",
    "We connect to the search engine and prepare the **official NIST trec_eval tool**. \n",
    "This tool is written in C, so we need to compile it using the `make` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee7369e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import subprocess\n",
    "from nltk.corpus import wordnet, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63e56cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- project configuration: change these paths to match your system ---\n",
    "\n",
    "# 1. search engine settings\n",
    "index_name = \"trec_product_search\"\n",
    "\n",
    "# 2. data file paths (where your corpus and queries are)\n",
    "corpus_path  = \"product_catalogue_esci.jsonl\"\n",
    "queries_path = \"qid2query.tsv\"\n",
    "qrels_path   = \"product-search-dev.qrels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "569273fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to 9.1.4\n"
     ]
    }
   ],
   "source": [
    "# --- part 1: connect to elasticsearch ---\n",
    "# we assume the database is running on the standard local port\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# check if the connection was successful\n",
    "if es.ping():\n",
    "    print(f\"connected to {es.info()['version']['number']}\")\n",
    "else:\n",
    "    print(\"ERROR with elasticsearch, check if running\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ca812",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Step 2: Setting up the Grading Tool\n",
    "For the final evaluation, we use the official **trec_eval** tool. \n",
    "Since this tool is built specifically for your operating system, the path to the \n",
    "executable file might change. If you are the examiner, please update the \n",
    "`trec_eval_executable` path below to point to your compiled version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411c3720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success: grading tool found at ./trec_eval/trec_eval\n",
      "‚úÖ success: tool is executable and responding.\n"
     ]
    }
   ],
   "source": [
    "# --- examiner: change this path if your trec_eval is in a different folder ---\n",
    "# this variable points directly to the compiled 'trec_eval' file\n",
    "trec_eval_executable = \"./trec_eval/trec_eval\"\n",
    "\n",
    "# --- check if the tool is accessible ---\n",
    "# we check if the file exists at the path provided above\n",
    "if os.path.exists(trec_eval_executable):\n",
    "    print(f\"success: grading tool found at {trec_eval_executable}\")\n",
    "    \n",
    "    # we test if the tool actually runs by asking for its help menu\n",
    "    # we use 'subprocess' to run a quick terminal command\n",
    "    try:\n",
    "        # this is like typing './trec_eval/trec_eval' in the terminal\n",
    "        test_run = subprocess.run([trec_eval_executable], capture_output=True, text=True)\n",
    "        print(\"‚úÖ success: tool is executable and responding.\")\n",
    "    except Exception as error_message:\n",
    "        print(f\"error: the tool was found but cannot run. error: {error_message}\")\n",
    "else:\n",
    "    print(f\"error: trec_eval not found at {trec_eval_executable}\")\n",
    "    print(\"please check the path or compile the tool in your terminal first\")\n",
    "\n",
    "# --- define the metrics we want to measure ---\n",
    "# we use the standard metrics for search engine quality:\n",
    "# 1. recip_rank: how high up is the first correct result? (MRR)\n",
    "# 2. recall.100: did we find the correct results in our top 100?\n",
    "# 3. ndcg_cut.100: how good is the overall ranking of the top 100?\n",
    "evaluation_metrics = \"-m recip_rank -m recall.100 -m ndcg_cut.100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e95ef6",
   "metadata": {},
   "source": [
    "## üìä Step 3: Indexing - Building the Product Database\n",
    "In this step, we prepare the search engine to receive our data. \n",
    "We define a **Custom Analyzer** called `product_cleaner`. This cleaner ensures that:\n",
    "* **Lowercase**: Searching for \"SONY\" or \"sony\" gives the same result.\n",
    "* **Stop Words**: Common words like \"a\", \"the\", and \"is\" are ignored so they don't slow down the search.\n",
    "* **Stemming**: Searching for \"gaming\" will also find products labeled \"gamer\" or \"game\".\n",
    "\n",
    "We merge the product description and bullet points into a single field called `contents` to give the search engine more data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a9eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_configurations = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"product_cleaner\": {\n",
    "          \"type\": \"custom\",\n",
    "          \"tokenizer\": \"standard\", # splits sentences into individual words\n",
    "          \"filter\": [\n",
    "              \"lowercase\",       # makes everything lower case\n",
    "              \"my_stop_words\",   # removes boring words (the, a, is)\n",
    "              \"my_stemmer\"       # chops words to their root (phones -> phone)\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"filter\": {\n",
    "        \"my_stemmer\": {\n",
    "            \"type\": \"stemmer\", \n",
    "            \"language\": \"english\"\n",
    "        },\n",
    "        \"my_stop_words\": {\n",
    "            \"type\": \"stop\", \n",
    "            \"stopwords\": \"_english_\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"id\": {\"type\": \"keyword\"}, # 'keyword' means we want the exact ID, no cleaning\n",
    "      \"title\": {\n",
    "          \"type\": \"text\", \n",
    "          \"analyzer\": \"product_cleaner\"\n",
    "      },\n",
    "      \"contents\": {\n",
    "          \"type\": \"text\", \n",
    "          \"analyzer\": \"product_cleaner\"\n",
    "      },\n",
    "      \"brand\": {\n",
    "          \"type\": \"text\", \n",
    "          \"analyzer\": \"product_cleaner\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0764bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting old index: trec_product_search\n",
      "‚úÖ success: fresh index 'trec_product_search' created.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. create the index in elasticsearch ---\n",
    "# first, we delete the index if it already exists (to start fresh)\n",
    "if es.indices.exists(index=index_name):\n",
    "    print(f\"deleting old index: {index_name}\")\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "# now we create the index using the configurations we defined above\n",
    "es.indices.create(index=index_name, body=index_configurations)\n",
    "print(f\"‚úÖ success: fresh index '{index_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting upload... please wait.\n",
      "reading data from: product_catalogue_esci.jsonl\n",
      "‚úÖ success: indexed 1118990 products.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. read the file and upload the data ---\n",
    "def prepare_products_for_upload():\n",
    "    \"\"\" \n",
    "    this helper function reads our json file line-by-line \n",
    "    and prepares a 'bundle' for the search engine.\n",
    "    \"\"\"\n",
    "    print(f\"reading data from: {corpus_path}\")\n",
    "    \n",
    "    with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # convert the text line into a python dictionary\n",
    "                item = json.loads(line)\n",
    "                \n",
    "                # identify the correct ID\n",
    "                # we prefer 'trecid' if it exists, otherwise we use 'product_id'\n",
    "                final_id = str(item.get(\"trecid\") or item.get(\"product_id\"))\n",
    "                \n",
    "                # combine the description and bullet points into one 'contents' field\n",
    "                description = item.get(\"product_description\", \"\") or \"\"\n",
    "                bullets = item.get(\"product_bullet_point\", \"\") or \"\"\n",
    "                full_text_contents = f\"{description} {bullets}\"\n",
    "\n",
    "                # yield (give back) the formatted product to the uploader\n",
    "                yield {\n",
    "                    \"_index\": index_name,\n",
    "                    \"_id\": final_id,\n",
    "                    \"_source\": {\n",
    "                        \"id\": final_id,\n",
    "                        \"title\": item.get(\"product_title\", \"\") or \"\",\n",
    "                        \"contents\": full_text_contents,\n",
    "                        \"brand\": item.get(\"product_brand\", \"\") or \"\"\n",
    "                    }\n",
    "                }\n",
    "            except Exception as e:\n",
    "                # if one line is broken, we skip it and keep going\n",
    "                continue\n",
    "\n",
    "# --- 4. run the bulk uploader ---\n",
    "# we use 'helpers.bulk' to upload many products at once (very fast)\n",
    "print(\"starting index, expect this to take 2-3 minutes\")\n",
    "success_count, error_count = helpers.bulk(es, prepare_products_for_upload(), chunk_size=5000)\n",
    "\n",
    "print(f\"success: indexed {success_count} products\")\n",
    "if error_count:\n",
    "    print(f\"error: {len(error_count)} products failed to index.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac53066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product_id': 'B003O0MNGC', 'product_title': 'Delta BreezSignature VFB25ACH 80 CFM Exhaust Bath Fan with Humidity Sensor', 'product_description': None, 'product_bullet_point': 'Virtually silent at less than 0.3 sones\\nPrecision engineered with DC brushless motor for extended reliability\\nEasily switch in and out of humidity sensing mode by toggling wall switch\\nENERGY STAR qualified for efficient cost-saving operation\\nPrecision engineered with DC brushless motor for extended reliability, this fan will outlast many household appliances', 'product_brand': 'DELTA ELECTRONICS (AMERICAS) LTD.', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 201460}\n",
      "{'product_id': 'B00MARNO5Y', 'product_title': 'Aero Pure AP80RVLW Super Quiet 80 CFM Recessed Fan/Light Bathroom Ventilation Fan with White Trim Ring', 'product_description': None, 'product_bullet_point': 'Super quiet 80CFM energy efficient fan virtually disappears into the ceiling leaving only a recessed light in view\\nMay be installed over shower when wired to a GFCI breaker and used with a PAR30L 75W (max) CFL\\nBulb not included. Accepts any of the following bulbs: 75W Max. PAR30, 14W Max. BR30 LED, or 75W Max. PAR30L (for use over tub/shower.)', 'product_brand': 'Aero Pure', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 320948}\n",
      "{'product_id': 'B011RX6PNO', 'product_title': 'Aero Pure AP120H-SL W Slim Fit 120 CFM Bathroom Fan with LED Light and Humidity Sensor, White Finish', 'product_description': None, 'product_bullet_point': 'Slim Fit Housing Fits Into 2\" X 6\" Ceiling Joists Or Greater\\nCountry of Origin: China\\nBrand name: Aero Pure\\nItem Dimensions: 11. 38\"L x 10. 5\"W x 5. 88\"H', 'product_brand': 'Aero Pure', 'product_color_name': 'White Finish', 'product_locale': 'us', 'trecid': 580421}\n",
      "{'product_id': 'B01MZIK0PI', 'product_title': 'Delta Electronics (Americas) Ltd. RAD80 Delta BreezRadiance Series 80 CFM Fan with Heater, 10.5W, 1.5 Sones', 'product_description': None, 'product_bullet_point': \"Quiet operation at 1.5 Sones\\nPrecision engineered with DC brushless motor for extended reliability, this Fan will outlast many household appliances\\nGalvanized steel construction resists corrosion, equipped with metal duct adapter\\nFan impeller Stops If obstructed, for safe worry-free operation\\nPeace of mind quality, performance and reliability from the world's largest DC brushless Fan Manufacturer\", 'product_brand': 'DELTA ELECTRONICS (AMERICAS) LTD.', 'product_color_name': 'With Heater', 'product_locale': 'us', 'trecid': 25698}\n",
      "{'product_id': 'B01N5Y6002', 'product_title': 'Delta Electronics (Americas) Ltd. GBR80HLED Delta BreezGreenBuilder Series 80 CFM Fan/Dimmable H, LED Light, Dual Speed & Humidity Sensor', 'product_description': None, 'product_bullet_point': 'Ultra energy-efficient LED module (11-watt equivalent to 60-watt incandescent light) included. Main light output-850 Lumens, 3000K\\nExtracts air at a rate of 80 CFM to properly ventilate bathrooms up to 80 sq. Ft., quiet operation at 0.8 sones\\nPrecision engineered with DC brushless motor for extended reliability, this Fan will outlast many household appliances\\nEnergy Star qualified for efficient cost-saving operation, galvanized steel construction resists corrosion\\nFan impeller Stops If obstructed, for safe worry-free operation, attractive grille gives your bathroom a fresh look', 'product_brand': 'DELTA ELECTRONICS (AMERICAS) LTD.', 'product_color_name': 'With LED Light, Dual Speed & Humidity Sensor', 'product_locale': 'us', 'trecid': 1203414}\n",
      "{'product_id': 'B07JY1PQNT', 'product_title': 'Aero Pure ABF80 L5 W ABF80L5 Ceiling Mount 80 CFM w/LED Light/Nightlight, Energy Star Certified, White Quiet Bathroom Ventilation Fan', 'product_description': None, 'product_bullet_point': 'Quiet 0.3 Sones, 80 CFM fan with choice of three designer grilles in White, Satin Nickel, or Oil Rubbed Bronze; Full 6 year warranty\\n10W 3000K 800 Lumens LED Light with 0.7W Nightlight included\\nInstallation friendly- Quick-mount adjustable metal bracket for new construction and retrofit; 4‚Äù, 5: and 6‚Äù metal duct adaptor included\\nMeets today‚Äôs demanding building specifications- ETL Listed for wet application, ENERGY STAR certified, CALGreen, JA-8 Compliant for CA Title 24, and ASHRAE 62.2 compliant\\nHousing dimensions- 10 2/5‚Äùx10 2/5‚Äùx 7 ¬Ω‚Äù; Grille dimensions- 13‚Äùx13‚Äù; Fits 2\"x8\" joists', 'product_brand': 'Aero Pure', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 1432374}\n",
      "{'product_id': 'B07QJ7WYFQ', 'product_title': 'Panasonic FV-08VRE2 Ventilation Fan with Recessed LED (Renewed)', 'product_description': None, 'product_bullet_point': 'The design solution for Fan/light combinations\\nEnergy Star rated architectural grade recessed Fan/LED light\\nQuiet, energy efficient and powerful 80 CFM ventilation hidden above the Ceiling\\nLED lamp is dimmable\\nBeautiful Lighting with 6-1/2‚Äùaperture and advanced luminaire design', 'product_brand': 'Panasonic', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 1093837}\n",
      "{'product_id': 'B07RH6Z8KW', 'product_title': 'Delta Electronics RAD80L BreezRadiance 80 CFM Heater/Fan/Light Combo White (Renewed)', 'product_description': 'This pre-owned or refurbished product has been professionally inspected and tested to work and look like new. How a product becomes part of Amazon Renewed, your destination for pre-owned, refurbished products: A customer buys a new product and returns it or trades it in for a newer or different model. That product is inspected and tested to work and look like new by Amazon-qualified suppliers. Then, the product is sold as an Amazon Renewed product on Amazon. If not satisfied with the purchase, renewed products are eligible for replacement or refund under the Amazon Renewed Guarantee.', 'product_bullet_point': 'Quiet operation at 1.5 sones\\nBuilt-in thermostat regulates temperature. Energy efficiency at 7.6 CFM/Watt\\nPrecision engineered with DC brushless motor for extended reliability, this fan will outlast many household appliances\\nGalvanized steel construction resists corrosion\\nDuct: Detachable 4-inch Plastic Duct Adapter', 'product_brand': 'DELTA ELECTRONICS (AMERICAS) LTD.', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 89934}\n",
      "{'product_id': 'B07WDM7MQQ', 'product_title': 'Homewerks 7140-80 Bathroom Fan Ceiling Mount Exhaust Ventilation, 1.5 Sones, 80 CFM, White', 'product_description': None, 'product_bullet_point': 'OUTSTANDING PERFORMANCE: This Homewerk\\'s bath fan ensures comfort in your home by quietly eliminating moisture and humidity in the bathroom. This exhaust fan is 1. 5 sone at 110 CFM which means it‚Äôs able to manage spaces up to 110 square feet\\nBATH FANS HELPS REMOVE HARSH ODOR: When cleaning the bathroom or toilet, harsh chemicals are used and they can leave an obnoxious odor behind. Homewerk‚Äôs bathroom fans can help remove this odor with its powerful ventilation\\nBUILD QUALITY: Designed to be corrosion resistant with its galvanized steel construction featuring a grille modern style.\\nEASY INSTALLATION: This exhaust bath fan is easy to install with its no-cut design and ceiling mount ventilation. Ceiling Opening (L) 7-1/2 in x Ceiling Opening (W) 7-1/4 x Ceiling Opening (H) 5-3/4 in and a 4\" round duct connector.\\nHOMEWERKS TRUSTED QUALITY: Be confident in the quality and construction of each and every one of our products. We ensure that all of our products are produced and certified to regional, national and international industry standards. We are proud of the products we sell, you will be too. 3 Year Limited', 'product_brand': 'Homewerks', 'product_color_name': 'White', 'product_locale': 'us', 'trecid': 1605771}\n",
      "{'product_id': 'B0188A3QRM', 'product_title': 'Amazon Basics Woodcased #2 Pencils, Unsharpened, HB Lead - Box of 144, Bulk Box', 'product_description': None, 'product_bullet_point': '144 woodcase #2 HB pencils made from high-quality wood for clean, easy sharpening\\nStrong medium-soft lead produces long-lasting, smooth, readable strokes\\nRounded hexagonal shape with satin-smooth finish for a secure, comfortable grip\\nSoft, smudge-free, latex-free eraser secured to the end for conveniently wiping away mistakes', 'product_brand': 'Amazon Basics', 'product_color_name': 'Yellow', 'product_locale': 'us', 'trecid': 570887}\n",
      "{'product_id': 'B075VXJ9VG', 'product_title': 'BAZIC Pencil #2 HB Pencils, Latex Free Eraser, Wood Free Yellow Unsharpened Pencils for Exam School Office (12/Pack), 1-Pack', 'product_description': '<p><strong>BACK TO BAZIC</strong></p><p>Our goal is to provide each customer with long-lasting supplies at an affordable cost. Since 1998, we‚Äôve delivered on this promise and will only continue to improve every year. We‚Äôve built our brand on integrity and quality, so customers know exactly what to expect.</p> <p><strong>COMMITTED TO VALUES</strong></p><p>We are a value-driven company, guided by the principles of excellence through strong product design at low cost. Our commitment to these values is reflected in our dedication to improving current products and developing new exciting products for our consumers.</p> <p><strong>FOCUSED ON OUR MISSION</strong></p><p>Our currency is ideas. We thrive on imagination, passion and leadership. We have great products and will to continue to rise with our customer expectations.</p> <p><strong>SUCCESS BASED ON SATISFACTION</strong></p><p>Each and every product we send out, we expect our 100% customer satisfaction. While our supplies are sourced from all across the world, our success stems from individual consumer fulfillment. We create products that people want to recommend to others.</p>', 'product_bullet_point': '&#11088; UN-SHARPENED #2 PREMIUM PENCILS. Each pack comes with 12 un-sharpened pencils. Unlike most others out there, these allow kids the simple joy of sharpening a brand new pencil for the very 1st time!\\n&#11088; CLASSIC BARREL. Made from premium-quality wood pencil is bonded with a break-resistant number two core for smooth writing as easily erased. Hexagonal shape prevents rolling and comfortable to hold.\\n&#11088; QUALITY. Pencils are #2 HB for general writing, drawing and sketching. Pencils glide smoothly over paper and is highly break resistant. Pencils include a smudge-resistant eraser top for convenience.\\n&#11088; LATEX-FREE ERASER. The smudge-less eraser is latex-free, which provides enough toughness for heavy erasures. These smudge-free erasers wipe the page clean, making corrections easy and fast.\\n&#11088; WIDE APPLICATION. Suitable for all general writing applications such as notes, letters, and you can use it for office, classroom, home and other occasions.', 'product_brand': 'BAZIC Products', 'product_color_name': '12-count', 'product_locale': 'us', 'trecid': 602674}\n",
      "{'product_id': 'B07G7F6JZ6', 'product_title': 'Emraw Pre Sharpened Round Primary Size No 2 Jumbo Pencils for Preschoolers, Elementary Kids - Pack of 8 Premium Fat Pencils', 'product_description': '<p><b>Emraw Pre-Sharpened #2 HB Wood Pencils - Pack of 8 Pre-Schoolers Pencils</b></p><p>Looking for pencils for kid, office or every day general purpose repetitive use? Tired of pencils that do not sharpen well? Disappointed having broken leads repeatedly? Or, looking for pencils that require less sharpening and lasts longer?</p><p>Search no further, Emraw num 2 jumbo pencils pack have you covered. You just found the best deal. You will love them. Just the right size for pre-kindergarten toddlers. Perfect for elderly hands having difficulty grasping smaller items. Each pencil is pre-sharpened so you can literally pick straight from the box and start using. HB (no2) hardness grading with thicker leads make them perfect for most types of writing or sketching.</p><p>Made of high quality non-toxic cedar wood so they sharpen nicely with any quality dual-holed hand sharpener or adjustable electric sharpener, (not compatible with standard pencil sharpener). Rounded circular shape offers an effortless, fatigue-free writing experience.</p><p>Big ultra-smooth graphite core does not break easily, helps kids to grip securely, write smoothly and build language and motor skills. Applying normal pressure kids can wipe away mistaken strokes without a lot of effort. The soft, non-smudge rubbers are effective to erase completely and will not leave any pink residue behind after erasing unwanted marks. The eraser on top is held strongly with a ferrule and will not loosen easily, that keeps an eraser always in hand throughout its lifespan.</p><p>Use or gift these pencils to use in the classroom, work, or home for anything from keeping lists, making notes, sketch first drafts, brainstorm campaign ideas, filling in answers on an exam, coloring books as a highlighter, quick sketches of diy carpentry projects, solving sudoku or crossword puzzles.</p><p><b>Best N.2 Woodcase Pencils Supplies for You, Your Children, Students, Family, or Workmates, Order Now!!!</b></p>', 'product_bullet_point': '‚úì PACK OF 8 NUMBER 2 PRESHARPENED BEGINNERS PENCILS: Emraw round sharpened pencils set contains 2 packs of 4 general no.2 hb pencils with latex-free rubber erasers top, total 8 primary size yellow preschool pencils, good for little hands\\n‚úì SUPERIOR NATURAL GRIP AND FEEL: Rounded triangular wooden casing blends ergonomic design for kids small hands in mind that allows your beginner writer a firm grip to comfortably hold and practice to write, scribble or tracing for hours\\n‚úì CLASSIC YELLOW BARREL WOOD-CASED PENCILS: Premium pencils made from high-quality wood for easy clean sharpening, 3.25 mm thick break-resistant graphite lead requires less sharpening, produces dark long-lasting, readable, consistent strokes\\n‚úì EASILY ERASABLE - MAKES DO-OVERS A BREEZE: Unwanted marks are easy to erase, offers clean corrections without tearing the paper. Soft, non-smudge rubbers are effective to erase marks completely and will not leave any residue behind\\n‚úì VERSATILE WIDE APPLICATION: Suitable for kids, boys girls, teens, adults. Perfect for students in kindergarten school exam or college, teacher in classroom and general use: workshops, corporate office, meeting, sketching, writing, drawing', 'product_brand': 'Emraw', 'product_color_name': 'Yellow', 'product_locale': 'us', 'trecid': 648631}\n",
      "{'product_id': 'B07MGKC3DD', 'product_title': 'BIC Evolution Cased Pencil, #2 Lead, Gray Barrel, 24-Count (PGEBP241-BLK)', 'product_description': None, 'product_bullet_point': 'Premium #2 HB lead pencils with break-resistant lead and splinter-free barrels\\nDurable, long-lasting leads and erasers\\nLatex-free erasers easily erase stray marks\\nTrendy and modern gray barrels\\nPack of 24 certified non-toxic pencils ideal for home or classroom', 'product_brand': 'Design House', 'product_color_name': 'Gray', 'product_locale': 'us', 'trecid': 785913}\n",
      "{'product_id': 'B07NH2D2CP', 'product_title': 'Maped Essentials Triangular Graphite #2 Pencils, Pack of 12 (851779ZT)', 'product_description': None, 'product_bullet_point': 'Classic Yellow #2 Graphite Pencils with a modern twist!\\nHigh quality #2 / HB Graphite is break resistant & goes down smooth!\\nTriangular shape is more comfortable to hold and easier to use than a standard pencil, will not roll and is recommended by teachers!\\nSharpen easily in any standard pencil sharpener\\nCustomer will receive 12 pre-sharpened Graphite Pencils', 'product_brand': 'Maped Helix USA', 'product_color_name': 'Yellow', 'product_locale': 'us', 'trecid': 356779}\n",
      "{'product_id': 'B07Z78H162', 'product_title': 'BIC Xtra Fun Cased Pencil, 2 Lead, Assorted Barrel Colors, 48-Count', 'product_description': None, 'product_bullet_point': 'Kid-friendly pencils feature bright two-toned colored barrels to make writing fun\\nSmooth, break-resistant #2 lead pencils are ideal for standardized tests\\nSharpens first time, every time\\nLong-lasting leads and easy-to-erase, latex-free erasers\\nPMA certified and non-toxic, great pencils for the classroom', 'product_brand': 'BIC', 'product_color_name': None, 'product_locale': 'us', 'trecid': 125839}\n",
      "{'product_id': 'B084Q4R7SG', 'product_title': 'Holographic Pencils with Erasers Metallic Assorted Colors Wooden Glitter Pencils Optical Illusion Pencils HB Pencils (36 Pieces)', 'product_description': \"<br>36 Pieces holographic pencils <br>Enough quantity for you to use, replace and share with your families, friends and classmates. <br> <br>Shiny look: <br>These metallic wooden pencils would be glittering under the light, they are interesting enough to invite attention of boys and girls. <br> <br>Nice gifts: <br>Boys and girls may like these pencils with eraser as their gifts on birthday, Christmas, Easter and Children's Day, etc. <br> <br>Specifications: <br>Material: wood <br>Color: silver, gold, blue, purple and pink <br>Size: about 7.3 inch/ 18.5 cm in length <br> <br>Package includes: <br>36 x Holographic pencils <br> <br>Note: <br>Erasers are small parts topping on pencils, please keep them away from children under 3 years old.\", 'product_bullet_point': \"5 Colors: there are 36 pieces holographic pencils with erasers in different solid colors including silver, gold, blue, purple and pink, enough quantity to use, replace and share with friends and students; Please note that pencils are not pre-sharpened\\nGlitter under the light: these wooden pencils are painted with metallic colors, they would reach a shiny effect under the light, resembling magic pencils\\nBring fun to life: interesting stationery to stimulate the curiosity of boys and girls, promoting them to gain related knowledge, but please keep them away from children under 3 years old\\nComfortable to grip: these metallic pencils with eraser toppers are made of wood, each of them is approx. 7.3 inch/ 18.5 cm in length, proper size for adults, boys and girls to use\\nGood gifts: these wooden holographic pencils are nice gifts to boys and girls on birthday, Easter, Children's Day and so on, good prizes for various competition in school\", 'product_brand': 'Outus', 'product_color_name': None, 'product_locale': 'us', 'trecid': 1421611}\n",
      "{'product_id': 'B087J9MBXJ', 'product_title': 'YOTINO Pre-sharpened Wood Cased #2 HB Pencils - Box of 100', 'product_description': '</br>YOTINO Pre-sharpened #2 HB Pencils Pack of 100 </br> </br>Description </br>These HB pencils in bulk are perfect for restocking the writing materials in your office or classroom. Plus, if you‚Äôre an artist who frequently sketches, these are great to have. </br> </br>Whether you‚Äôre taking notes, making unique artwork, or sketching out a custom design, this is the best choice for premium quality pencils. </br> </br> </br>Feature: </br>Break-Resistant </br> The dense graphite cores make these pencils ideal for drawing, writing & sketching </br> </br>Durable Latex-Free Erasers </br>Will erase your marks without damaging your paper </br> </br>Sharpened & Ready-to-Use </br>Each pencil comes pre-sharpened, You can start writing, drawing, or sketching as soon as you open the box. </br> </br>Convenient Bulk Pack </br>You‚Äôll always have enough pencils for your office, classroom or home . </br> </br>Package Includes: </br>Pre-sharpened Wood Cased Pencils - Box of 100', 'product_bullet_point': 'Convenient Bulk Pack - Box of 100 count #2 HB yellow, wood-cased pencils with latex-free eraser - certified non-toxic. Bulk pack, Smooth write for Exams, School, Office.\\nBreak-Resistant - The classic design features soft #2 lead and the break-resistant lead writes smoothly and cleanly . ideal for drawing, writing & sketching.\\npre-sharpened - This set of writing utensils come pre-sharpened and ready to use immediately. They feature break-resistant cores to ensure easy and even sharpening. The hard lead core will not smear nor smudge, and are ideal for scantron tests and rough drafts.\\nWith Latex Free Erasers: Soft, smudge-free, latex-free eraser secured to the end for conveniently wiping away mistakes\\ncomfortable grip - Each pencil is finished in a satin matte coating, giving them a comfortable grip. These writing instruments are hexagonal in shape to ensure a comfortable grip when writing, scribbling, or doodling.', 'product_brand': 'N2', 'product_color_name': 'Yellow', 'product_locale': 'us', 'trecid': 1606734}\n",
      "{'product_id': 'B0891R2YFN', 'product_title': 'Wood-Cased #2 HB Pencils, Shuttle Art 600 Pack Sharpened Yellow Pencils with Erasers, Bulk Pack Graphite Pencils for School and Teacher Supplies, Writhing, Drawing and Sketching', 'product_description': None, 'product_bullet_point': '600 COUNT VALUE PACK: Shuttle Art 600 Pack #2 HB wood-cased yellow pencils in bulk are ideal choice for school, office and home to maintain daily pencil consumption. They are widely used in daily writhing, sketching, examination, marking, and more, especially for kids and teen writing in classroom and home.\\nPRE-SHARPENED & EASY SHARPENING: All the 600 count pencils are pre-sharpened, ready to use when get it, saving your time of preparing. They are also easy to be sharpened‚Äîpremium quality wood protecting the lead well and sharpens easily.\\nSMOOTH WRITING & BREAK RESISTANT: Standard #2 HB pencils are durable enough for daily use. They write smoothly with bold clear marks, no smudging, and can be wiped easily. Strong, break-resistant lead guarantee long time writing and sketching, and each pencil can be fully used, no wasting at all.\\nLATEX FREE PINK END ERASERS: Each pencil comes with a soft pink eraser in the end, convenient for you to wipe pencil marks at any time. No smudging or tearing paper, erase clearly and easily, and durable enough for a long time use. Conforms to ASTM-D4236, non-toxic and acid-free, safe for kids and adults.\\nSERVICE GUARANTEE: Your satisfaction is our top priority, please rest assured to purchase our products. If you are not satisfied with our products or have any questions, please feel free to contact us at any time.', 'product_brand': 'Shuttle Art', 'product_color_name': 'Yellow', 'product_locale': 'us', 'trecid': 299173}\n",
      "{'product_id': 'B08KXRY4DG', 'product_title': 'AHXML#2 HB Wood Cased Graphite Pencils, Pre-Sharpened with Free Erasers, Smooth write for Exams, School, Office, Drawing and Sketching, Pack of 48', 'product_description': \"<b>AHXML#2 HB Wood Cased Graphite Pencils, Pack of 48</b><br><br>Perfect for Beginners experienced graphic designers and professionals, kids Ideal for art supplies, drawing supplies, sketchbook, sketch pad, shading pencil, artist pencil, school supplies. <br><br><b>Package Includes</b><br>- 48 x Sketching Pencil<br> - 1 x Paper Boxed packaging<br><br>Our high quality, hexagonal shape is super lightweight and textured, producing smooth marks that erase well, and do not break off when you're drawing.<br><br><b>If you have any question or suggestion during using, please feel free to contact us.</b>\", 'product_bullet_point': '#2 HB yellow, wood-cased pencils:Box of 48 count. Made from high quality real poplar wood and 100% genuine graphite pencil core. These No 2 pencils come with 100% Non-Toxic latex free pink top erasers.\\nPRE-SHARPENED & EASY SHARPENING: All the 48 count pencils are pre-sharpened, ready to use when get it, saving your time of preparing.\\nThese writing instruments are hexagonal in shape to ensure a comfortable grip when writing, scribbling, or doodling.\\nThey are widely used in daily writhing, sketching, examination, marking, and more, especially for kids and teen writing in classroom and home.#2 HB wood-cased yellow pencils in bulk are ideal choice for school, office and home to maintain daily pencil consumption.\\nCustomer service:If you are not satisfied with our product or have any questions, please feel free to contact us.', 'product_brand': 'AHXML', 'product_color_name': None, 'product_locale': 'us', 'trecid': 1075707}\n",
      "{'product_id': 'B08R8LW1W2', 'product_title': 'HB pencils with eraser set 12 pack + 2 Erasers + 5 Sharpener,for School and Kids Writing pencil.(Green)', 'product_description': '<b>We made sure that we used high quality materials in manufacturing our pencil set.</b><br> <br> <b>Stationery set includes:</b><br> HB Pencils X 12<br> Pencil Sharpener X 5<br> Erasers X 2<br> Pencil case X 1<br> <br> All the stationery is packed in a cute pencil case,Which is easy to organize and carry.It is suitable for adults and kids,Whether it is in school,Office or out or travel,it is a good choice.<br> <br> For its quality and price,The stationery set is an absolute steal!<br> <br> We are committed to providing customers with the best customer service and the best shopping experience. If you are not satisfied with our products or have any quality problems, Please feel free to contact us and.<br> <br> Click the <b>\"add to shopping basket\"</b> Button,and you will immediately get High-quality Stationary set!', 'product_bullet_point': 'Value For Money:Suitable for Kids school pencil sets or adult drawing or handwriting pencil sets,Suit includes HB Pencils 12 Pack,5 Pencil Sharpeners and 2 Erasers 1 Pencil case,Sufficient for School Office or Personal writing and drawing projects.\\nPerfect Quality:The real original traditional wood and 100% graphite core have a fracture-resistant and smooth appearance, ensuring a firm and comfortable grip,High-quality rubber,steel blade sharpener,We use the best materials and craftsmanship to ensure that you are comfortable and assured during use.\\nMultiple Uses:Stationery pencil set can be used anywhere,And performs as well as any pencil from more expensive brands,When it comes to writing and drawing,It creates bold, dark lines,Great for school,office and home use,Our stationery set is something that both children and adults needs to have.\\nSuitable For Everyone:The product is great for Home,Classes,Office, Business,Kids,Adults,Artist,School,Nursery,Gift set etc.,We have equipped with a cute pencil bag, suitable to carry around.\\nSatisfactory Customer Service:We are committed to providing customers with the best customer service and the best shopping experience,If you are not satisfied with our products or have any quality problems, Please feel free to contact us and.', 'product_brand': 'VICGP', 'product_color_name': 'Green', 'product_locale': 'us', 'trecid': 504489}\n"
     ]
    }
   ],
   "source": [
    "# first look into the corpus\n",
    "with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "   for i in range(20):\n",
    "      print(json.loads(f.readline()))\n",
    "      \n",
    "\n",
    "# we find the fields 'product_id', 'product_title',  'product_description', 'product_bullet_point', 'product_brand', 'product_color_name', 'product_locale', 'trecid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392026d",
   "metadata": {},
   "source": [
    "## üß† Strategy A: Semantic Search (Query Expansion)\n",
    "The goal of this strategy is to solve the **\"Vocabulary Mismatch\"** problem. \n",
    "For example, if a user searches for \"sneakers,\" but a product is listed as \"running shoes,\" a standard search might miss it. \n",
    "\n",
    "We use the **NLTK WordNet** library to:\n",
    "1. Identify the words in the user's query.\n",
    "2. Find synonyms (synsets) for those words.\n",
    "3. Add those synonyms to the search query to \"cast a wider net.\"\n",
    "\n",
    "We also apply **Field Boosting** here, making sure the `title` and `brand` are still weighted more heavily than the synonyms found in the `contents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84df033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading wordnet dictionary...\n",
      "original: mobile phone\n",
      "expanded: sound telephone earphone Mobile River mobile telephone set earpiece speech sound headphone phone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/marvin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/marvin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/marvin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. setup the synonym dictionary ---\n",
    "# we check if the wordnet data is already downloaded\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    print(\"downloading wordnet dictionary...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "# we create a list of common 'stop words' (like 'the', 'is') to ignore\n",
    "english_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# we create a 'memory' (cache) so we don't have to look up the same word twice\n",
    "synonym_memory_cache = {}\n",
    "\n",
    "def get_synonyms_for_query(user_text):\n",
    "    \"\"\"\n",
    "    this function takes a sentence and adds synonyms for each word.\n",
    "    example: 'phone' -> 'phone telephone cellular'\n",
    "    \"\"\"\n",
    "    individual_words = user_text.split()\n",
    "    expanded_words_list = []\n",
    "    \n",
    "    for word in individual_words:\n",
    "        # always keep the original word the user typed!\n",
    "        expanded_words_list.append(word)\n",
    "        \n",
    "        # if we already looked up this word, get it from memory\n",
    "        if word in synonym_memory_cache:\n",
    "            expanded_words_list.extend(synonym_memory_cache[word])\n",
    "            continue\n",
    "            \n",
    "        # we only look for synonyms for important words (not 'the', 'a', etc.)\n",
    "        if word.lower() not in english_stop_words and len(word) > 2:\n",
    "            found_synonyms = set()\n",
    "            try:\n",
    "                # we look for 'nouns' (objects) specifically\n",
    "                for synset in wordnet.synsets(word, pos=wordnet.NOUN):\n",
    "                    for lemma in synset.lemmas():\n",
    "                        # wordnet uses underscores like 'cell_phone', we replace with spaces\n",
    "                        clean_synonym = lemma.name().replace('_', ' ')\n",
    "                        \n",
    "                        # add it to our set if it's actually a different word\n",
    "                        if clean_synonym.lower() != word.lower():\n",
    "                            found_synonyms.add(clean_synonym)\n",
    "            except:\n",
    "                pass # if wordnet fails, we just move to the next word\n",
    "            \n",
    "            # store the results in our memory cache\n",
    "            synonym_list = list(found_synonyms)\n",
    "            synonym_memory_cache[word] = synonym_list\n",
    "            expanded_words_list.extend(synonym_list)\n",
    "            \n",
    "    # remove any duplicates and join the words back into one string\n",
    "    return \" \".join(list(set(expanded_words_list)))\n",
    "\n",
    "def search_strategy_a_semantic(query_text, result_limit=100):\n",
    "    \"\"\"\n",
    "    runs the search using our synonym expansion and field boosting.\n",
    "    \"\"\"\n",
    "    # first, expand the query\n",
    "    rich_query = get_synonyms_for_query(query_text)\n",
    "    \n",
    "    # define the search body for elasticsearch\n",
    "    search_body = {\n",
    "        \"size\": result_limit,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": rich_query,\n",
    "                # we boost the title (3x) and brand (2x) because they are most important\n",
    "                \"fields\": [\"title^3\", \"contents\", \"brand^2\"],\n",
    "                # we use 'or' because a document won't have ALL synonyms\n",
    "                \"operator\": \"or\" \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # execute the search\n",
    "    response = es.search(index=index_name, body=search_body)\n",
    "    return response['hits']['hits']\n",
    "\n",
    "# quick test to see if it works\n",
    "test_query = \"mobile phone\"\n",
    "print(f\"original: {test_query}\")\n",
    "print(f\"expanded: {get_synonyms_for_query(test_query)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d34b32",
   "metadata": {},
   "source": [
    "## üöÄ Strategy B: Structural Boosting (Optimized Weights)\n",
    "This strategy focuses on the **Importance of Fields**. We rely on the high quality of specific metadata.\n",
    "\n",
    "Instead of expanding the query with synonyms, we search for the exact words the user provided but tell the engine which fields \"matter\" more. We use **Field Boosting** (using the `^` symbol) to assign weights:\n",
    "* **Title (^3)**: The most important indicator of relevance.\n",
    "* **Brand (^2)**: Very important for filtered searches.\n",
    "* **Color (^1.5)**: Important for specific aesthetic queries.\n",
    "* **Contents (^1)**: Provides context but is secondary to the title.\n",
    "\n",
    "We use the `best_fields` type, which ensures that a product gets a high score if one of its fields is a perfect match for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ad65b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing structural boosting for: 'black wireless headphones'\n"
     ]
    }
   ],
   "source": [
    "def search_strategy_b_boosting(user_query, result_limit=100):\n",
    "    \"\"\"\n",
    "    executes the search using exact terms but with prioritized field weights.\n",
    "    we include the 'color' field here for more precise matching.\n",
    "    \"\"\"\n",
    "    \n",
    "    # we build the search request for elasticsearch\n",
    "    search_body = {\n",
    "        \"size\": result_limit,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": user_query,\n",
    "                # we define our boosting weights here:\n",
    "                \"fields\": [\n",
    "                    \"title^3\",    # title is 3x more important\n",
    "                    \"brand^2\",    # brand is 2x more important\n",
    "                    \"color^1.5\",  # color is 1.5x more important\n",
    "                    \"contents\"    # contents has the standard weight (1)\n",
    "                ],\n",
    "                \n",
    "                # 'best_fields' finds the single field that matches best \n",
    "                # and uses its score. this is great for product search.\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # execute the search against our index\n",
    "    response = es.search(index=index_name, body=search_body)\n",
    "    \n",
    "    # return the list of hits\n",
    "    return response['hits']['hits']\n",
    "\n",
    "# simple test run\n",
    "test_search = \"black wireless headphones\"\n",
    "print(f\"testing structural boosting for: '{test_search}'\")\n",
    "# results = search_strategy_b_boosting(test_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee21fb",
   "metadata": {},
   "source": [
    "## üìä Final Step: Scientific Comparison of Strategies\n",
    "In this final stage, we perform a rigorous experiment to see which strategy performs best. \n",
    "We evaluate the performance using three industry-standard metrics:\n",
    "* **MRR (Mean Reciprocal Rank)**: Measures how quickly the first relevant result appears.\n",
    "* **Recall@100**: Measures what percentage of relevant products we actually found in the top 100.\n",
    "* **NDCG@100**: Measures the overall quality and \"ranking order\" of the top 100 results.\n",
    "\n",
    "We will generate three **Run Files** (`.txt` files) in the standard TREC format and then pass them \n",
    "to the `trec_eval` tool for the final grades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "254532a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- starting the final scientific experiment ---\n",
      "loading answer key from: product-search-dev.qrels.txt\n",
      "loading queries from: qid2query.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A/tmp/ipykernel_110876/606466298.py:54: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  results_baseline = es.search(index=index_name, size=100, body={\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:19<00:00, 50.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìä --- FINAL SCIENTIFIC SCORES --- üìä\n",
      "\n",
      ">>> 1. BASELINE (The Control)\n",
      "recip_rank            \tall\t0.4039\n",
      "recall_100            \tall\t0.3650\n",
      "ndcg_cut_100          \tall\t0.2829\n",
      "\n",
      ">>> 2. STRATEGY A (WordNet / Semantic)\n",
      "recip_rank            \tall\t0.2726\n",
      "recall_100            \tall\t0.2536\n",
      "ndcg_cut_100          \tall\t0.1856\n",
      "\n",
      ">>> 3. STRATEGY B (Boosting / Structural)\n",
      "recip_rank            \tall\t0.4526\n",
      "recall_100            \tall\t0.3858\n",
      "ndcg_cut_100          \tall\t0.3079\n"
     ]
    }
   ],
   "source": [
    "def run_the_final_experiment(query_limit=1000):\n",
    "    \"\"\"\n",
    "    this function runs all three strategies and compares them \n",
    "    using the trec_eval tool.\n",
    "    \"\"\"\n",
    "    print(\"--- starting the final scientific experiment ---\")\n",
    "    \n",
    "    # 1. load the answer key (qrels) so we know which products are actually correct\n",
    "    # we only want to test queries that have known correct answers\n",
    "    print(f\"loading answer key from: {qrels_path}\")\n",
    "    correct_answers_map = collections.defaultdict(set)\n",
    "    valid_query_ids = set()\n",
    "    \n",
    "    with open(qrels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            # if the relevance score is greater than 0, it is a correct match\n",
    "            if len(parts) == 4 and int(parts[3]) > 0:\n",
    "                valid_query_ids.add(parts[0])\n",
    "                correct_answers_map[parts[0]].add(parts[2])\n",
    "\n",
    "    # 2. load the user queries from the tsv file\n",
    "    print(f\"loading queries from: {queries_path}\")\n",
    "    with open(queries_path, 'r') as f:\n",
    "        all_query_lines = f.readlines()\n",
    "\n",
    "    # 3. prepare the files where we will save our search results (run files)\n",
    "    # we open them in 'write' mode to start fresh\n",
    "    file_baseline = open(\"run_baseline.txt\", \"w\")\n",
    "    file_wordnet  = open(\"run_wordnet.txt\", \"w\")\n",
    "    file_boosting = open(\"run_boosting.txt\", \"w\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    progress_bar = tqdm(total=query_limit)\n",
    "    \n",
    "    # 4. the main experiment loop\n",
    "    for line in all_query_lines:\n",
    "        if processed_count >= query_limit: \n",
    "            break\n",
    "            \n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) < 2: \n",
    "            continue\n",
    "            \n",
    "        query_id = parts[0]\n",
    "        query_text = parts[1]\n",
    "        \n",
    "        # skip this query if we don't have an answer key for it\n",
    "        if query_id not in valid_query_ids: \n",
    "            continue\n",
    "            \n",
    "        # --- RUN 1: BASELINE (Control Group) ---\n",
    "        # we search with equal weights and no synonyms\n",
    "        results_baseline = es.search(index=index_name, size=100, body={\n",
    "            \"query\": {\"multi_match\": {\"query\": query_text, \"fields\": [\"title\", \"contents\", \"brand\"]}}\n",
    "        })['hits']['hits']\n",
    "        \n",
    "        for i, hit in enumerate(results_baseline):\n",
    "            # write in trec format: qid Q0 doc_id rank score run_name\n",
    "            file_baseline.write(f\"{query_id} Q0 {hit['_id']} {i+1} {hit['_score']:.4f} baseline\\n\")\n",
    "            \n",
    "        # --- RUN 2: WORDNET (Strategy A) ---\n",
    "        results_wordnet = search_strategy_a_semantic(query_text, result_limit=100)\n",
    "        for i, hit in enumerate(results_wordnet):\n",
    "            file_wordnet.write(f\"{query_id} Q0 {hit['_id']} {i+1} {hit['_score']:.4f} wordnet\\n\")\n",
    "            \n",
    "        # --- RUN 3: BOOSTING (Strategy B) ---\n",
    "        results_boosting = search_strategy_b_boosting(query_text, result_limit=100)\n",
    "        for i, hit in enumerate(results_boosting):\n",
    "            file_boosting.write(f\"{query_id} Q0 {hit['_id']} {i+1} {hit['_score']:.4f} boosting\\n\")\n",
    "            \n",
    "        processed_count += 1\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # close all files to save the data\n",
    "    progress_bar.close()\n",
    "    file_baseline.close(); file_wordnet.close(); file_boosting.close()\n",
    "    \n",
    "    # 5. call the official trec_eval tool (the one you built in WSL)\n",
    "    print(\"\\n\\nüìä --- FINAL SCIENTIFIC SCORES --- üìä\")\n",
    "    \n",
    "    # we use the executable path and metrics we defined in step 2\n",
    "    # the command looks like: ./trec_eval/trec_eval -m ... qrels_file run_file\n",
    "    \n",
    "    print(\"\\n>>> 1. BASELINE (The Control)\")\n",
    "    !{trec_eval_executable} {evaluation_metrics} {qrels_path} run_baseline.txt\n",
    "    \n",
    "    print(\"\\n>>> 2. STRATEGY A (WordNet / Semantic)\")\n",
    "    !{trec_eval_executable} {evaluation_metrics} {qrels_path} run_wordnet.txt\n",
    "    \n",
    "    print(\"\\n>>> 3. STRATEGY B (Boosting / Structural)\")\n",
    "    !{trec_eval_executable} {evaluation_metrics} {qrels_path} run_boosting.txt\n",
    "\n",
    "# --- run the finale! ---\n",
    "run_the_final_experiment(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2b56063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- starting grid search on 200 queries ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optimizing weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 225/225 [01:55<00:00,  1.94it/s, best_ndcg=0.2264]\n"
     ]
    }
   ],
   "source": [
    "def big_parameter_tuning(sample_size=200):\n",
    "    \"\"\"\n",
    "    this function tests every combination of weights.\n",
    "    it is now cleaned to avoid 'spamming' the output.\n",
    "    \"\"\"\n",
    "    print(f\"--- starting grid search on {sample_size} queries ---\")\n",
    "    \n",
    "    title_weights       = [1, 2, 3, 4, 5]\n",
    "    description_weights = [1, 2, 3]\n",
    "    brand_weights       = [1, 2, 3, 4, 5]\n",
    "    color_weights       = [1, 2, 3]\n",
    "    \n",
    "    best_ndcg = 0\n",
    "    best_weights = {}\n",
    "\n",
    "    # load the answer key\n",
    "    qrels = collections.defaultdict(set)\n",
    "    with open(qrels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            p = line.split()\n",
    "            if int(p[3]) > 0: qrels[p[0]].add(p[2])\n",
    "\n",
    "    # load queries\n",
    "    with open(queries_path, 'r') as f:\n",
    "        all_lines = f.readlines()\n",
    "        sample_queries = []\n",
    "        for line in all_lines:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2 and parts[0] in qrels:\n",
    "                sample_queries.append(parts)\n",
    "            if len(sample_queries) >= sample_size: break\n",
    "\n",
    "    total_combos = len(title_weights) * len(description_weights) * len(brand_weights) * len(color_weights)\n",
    "    \n",
    "    # tqdm(leave=True) and removing prints inside the loop prevents the 'broken output'\n",
    "    pbar = tqdm(total=total_combos, desc=\"optimizing weights\")\n",
    "\n",
    "    for t_w in title_weights:\n",
    "        for d_w in description_weights:\n",
    "            for b_w in brand_weights:\n",
    "                for c_w in color_weights:\n",
    "                    scores = []\n",
    "                    for qid, txt in sample_queries:\n",
    "                        # FIX: size is moved inside the body to stop DeprecationWarnings\n",
    "                        search_body = {\n",
    "                            \"size\": 10,\n",
    "                            \"query\": {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": txt,\n",
    "                                    \"fields\": [\n",
    "                                        f\"title^{t_w}\", \n",
    "                                        f\"contents^{d_w}\", \n",
    "                                        f\"brand^{b_w}\", \n",
    "                                        f\"color^{c_w}\"\n",
    "                                    ],\n",
    "                                    \"type\": \"best_fields\"\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        # FIX: we only pass index and body\n",
    "                        res = es.search(index=index_name, body=search_body)['hits']['hits']\n",
    "                        \n",
    "                        dcg = sum([1.0/math.log2(i+2) for i,h in enumerate(res) if h['_id'] in qrels[qid]])\n",
    "                        idcg = sum([1.0/math.log2(i+2) for i in range(min(len(qrels[qid]), 10))])\n",
    "                        if idcg > 0:\n",
    "                            scores.append(dcg/idcg)\n",
    "                    \n",
    "                    avg_ndcg = sum(scores) / len(scores) if scores else 0\n",
    "                    \n",
    "                    if avg_ndcg > best_ndcg:\n",
    "                        best_ndcg = avg_ndcg\n",
    "                        best_weights = {\"title\": t_w, \"contents\": d_w, \"brand\": b_w, \"color\": c_w}\n",
    "                        # update progress bar with the current best score\n",
    "                        pbar.set_postfix({\"best_ndcg\": f\"{best_ndcg:.4f}\"})\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    pbar.close()\n",
    "    return best_weights\n",
    "\n",
    "# run the tuner\n",
    "final_optimized_weights = big_parameter_tuning(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaeb9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_strategy_c_optimized(user_query, result_limit=100):\n",
    "    \"\"\"\n",
    "    the ultimate search strategy using weights found by the grid search.\n",
    "    \"\"\"\n",
    "    # we pull the weights from the 'final_optimized_weights' variable\n",
    "    t_w = final_optimized_weights.get('title', 3)\n",
    "    d_w = final_optimized_weights.get('contents', 1)\n",
    "    b_w = final_optimized_weights.get('brand', 2)\n",
    "    c_w = final_optimized_weights.get('color', 1)\n",
    "\n",
    "    search_body = {\n",
    "        \"size\": result_limit,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": user_query,\n",
    "                \"fields\": [\n",
    "                    f\"title^{t_w}\", \n",
    "                    f\"contents^{d_w}\", \n",
    "                    f\"brand^{b_w}\", \n",
    "                    f\"color^{c_w}\"\n",
    "                ],\n",
    "                \"type\": \"best_fields\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=index_name, body=search_body)\n",
    "    return response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecf6c7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üî¨ starting the final scientific experiment ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running search strategies: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:22<00:00, 45.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "üìä --- FINAL SCIENTIFIC GRADES --- üìä\n",
      "\n",
      ">>> 1. BASELINE (Control)\n",
      "recip_rank            \tall\t0.4039\n",
      "recall_100            \tall\t0.3650\n",
      "ndcg_cut_100          \tall\t0.2829\n",
      "\n",
      ">>> 2. STRATEGY A (WordNet)\n",
      "recip_rank            \tall\t0.2726\n",
      "recall_100            \tall\t0.2536\n",
      "ndcg_cut_100          \tall\t0.1856\n",
      "\n",
      ">>> 3. STRATEGY B (Manual Boosting)\n",
      "recip_rank            \tall\t0.4526\n",
      "recall_100            \tall\t0.3858\n",
      "ndcg_cut_100          \tall\t0.3079\n",
      "\n",
      ">>> 4. OPTIMIZED (ML Grid Search Results)\n",
      "recip_rank            \tall\t0.4549\n",
      "recall_100            \tall\t0.4027\n",
      "ndcg_cut_100          \tall\t0.3181\n"
     ]
    }
   ],
   "source": [
    "def run_final_scientific_experiment(query_limit=1000):\n",
    "    print(\"--- üî¨ starting the final scientific experiment ---\")\n",
    "    \n",
    "    # 1. create the result files\n",
    "    file_base = open(\"run_baseline.txt\", \"w\")\n",
    "    file_wordnet = open(\"run_wordnet.txt\", \"w\")\n",
    "    file_manual = open(\"run_manual_boost.txt\", \"w\")\n",
    "    file_optimized = open(\"run_ml_optimized.txt\", \"w\")\n",
    "    \n",
    "    # 2. load queries and answer key\n",
    "    qrels = collections.defaultdict(set)\n",
    "    with open(qrels_path, 'r') as f:\n",
    "        for line in f:\n",
    "            p = line.split()\n",
    "            if int(p[3]) > 0: qrels[p[0]].add(p[2])\n",
    "\n",
    "    with open(queries_path, 'r') as f:\n",
    "        all_query_lines = f.readlines()\n",
    "\n",
    "    processed = 0\n",
    "    # we clean up the tqdm output to prevent empty rows\n",
    "    pbar = tqdm(total=query_limit, desc=\"running search strategies\", leave=True)\n",
    "    \n",
    "    for line in all_query_lines:\n",
    "        if processed >= query_limit: break\n",
    "        \n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) < 2 or parts[0] not in qrels: continue\n",
    "        \n",
    "        qid, txt = parts[0], parts[1]\n",
    "        \n",
    "        # --- A. Baseline ---\n",
    "        # we pass size inside the body to avoid deprecation warnings\n",
    "        res_base = es.search(index=index_name, body={\n",
    "            \"size\": 100, \n",
    "            \"query\": {\"multi_match\": {\"query\": txt, \"fields\": [\"title\", \"contents\", \"brand\"]}}\n",
    "        })['hits']['hits']\n",
    "        for i, h in enumerate(res_base):\n",
    "            file_base.write(f\"{qid} Q0 {h['_id']} {i+1} {h['_score']:.4f} baseline\\n\")\n",
    "            \n",
    "        # --- B. WordNet (Strategy A) ---\n",
    "        res_wn = search_strategy_a_semantic(txt, result_limit=100)\n",
    "        for i, h in enumerate(res_wn):\n",
    "            file_wordnet.write(f\"{qid} Q0 {h['_id']} {i+1} {h['_score']:.4f} wordnet\\n\")\n",
    "            \n",
    "        # --- C. Manual Boosting (Strategy B) ---\n",
    "        res_man = search_strategy_b_boosting(txt, result_limit=100)\n",
    "        for i, h in enumerate(res_man):\n",
    "            file_manual.write(f\"{qid} Q0 {h['_id']} {i+1} {h['_score']:.4f} manual\\n\")\n",
    "            \n",
    "        # --- D. ML Optimized (The Winner) ---\n",
    "        res_opt = search_strategy_c_optimized(txt, result_limit=100)\n",
    "        for i, h in enumerate(res_opt):\n",
    "            file_optimized.write(f\"{qid} Q0 {h['_id']} {i+1} {h['_score']:.4f} optimized\\n\")\n",
    "            \n",
    "        processed += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    file_base.close(); file_wordnet.close(); file_manual.close(); file_optimized.close()\n",
    "    \n",
    "    # 3. Grade everything with trec_eval\n",
    "    print(\"\\n\\nüìä --- FINAL SCIENTIFIC GRADES --- üìä\")\n",
    "    \n",
    "    # we use the metrics and tool path we defined in Step 2\n",
    "    cmd_prefix = f\"{trec_eval_executable} {evaluation_metrics} {qrels_path}\"\n",
    "    \n",
    "    print(\"\\n>>> 1. BASELINE (Control)\")\n",
    "    !{cmd_prefix} run_baseline.txt\n",
    "    \n",
    "    print(\"\\n>>> 2. STRATEGY A (WordNet)\")\n",
    "    !{cmd_prefix} run_wordnet.txt\n",
    "    \n",
    "    print(\"\\n>>> 3. STRATEGY B (Manual Boosting)\")\n",
    "    !{cmd_prefix} run_manual_boost.txt\n",
    "    \n",
    "    print(\"\\n>>> 4. OPTIMIZED (ML Grid Search Results)\")\n",
    "    !{cmd_prefix} run_ml_optimized.txt\n",
    "\n",
    "# Execute the final run\n",
    "run_final_scientific_experiment(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
